{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac499ea7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Updated: aruco_dataset_builder_splitter.py\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from aruco_box_pose_estimation import CubePoseEstimator\n",
    "from utility.rotation_utils import rotation_matrix_to_6d\n",
    "import time\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8004f16",
   "metadata": {},
   "source": [
    "PREREQS AND DECS AND INITIALS BLAAABLABLABLBLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35ff1c8",
   "metadata": {
    "title": "Configuration"
   },
   "outputs": [],
   "source": [
    "with open(\"GlobVar.json\", \"r\") as file:\n",
    "    gv = json.load(file)\n",
    "batch = gv['batch']\n",
    "BATCH_ID = batch\n",
    "FRAME_STEP = 1  # Skip every N frames to reduce redundancy\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "TRAIN_RATIO = 1 - VAL_RATIO - TEST_RATIO\n",
    "AUG_PER_FRAME = 1\n",
    "VIDEO_PATH = \"video/raw/ArUco.mp4\"\n",
    "BATCH_FOLDER = f\"dataset/batch{BATCH_ID}\"\n",
    "UNSPLIT_FOLDER = os.path.join(BATCH_FOLDER, \"unsplit\")\n",
    "IMAGES_FOLDER = os.path.join(UNSPLIT_FOLDER, \"images\")\n",
    "LABELS_PATH = os.path.join(UNSPLIT_FOLDER, \"labels.csv\")\n",
    "\n",
    "os.makedirs(IMAGES_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ab2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness_contrast(image, alpha_range=(0.8, 1.2), beta_range=(-30, 30)):\n",
    "    \"\"\"Randomly adjusts brightness and contrast.\"\"\"\n",
    "    alpha = np.random.uniform(*alpha_range)  # Contrast\n",
    "    beta = np.random.uniform(*beta_range)    # Brightness\n",
    "    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c861a0b",
   "metadata": {},
   "source": [
    "MAKE THE LABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c58ad33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished reading video and writing labels.\n",
      "üïí Time took: 171s\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "estimator = CubePoseEstimator()\n",
    "frame_idx = 0\n",
    "write_idx = 0\n",
    "now = []\n",
    "now.append(time.time())\n",
    "\n",
    "with open(LABELS_PATH, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_name', 'x', 'y', 'z', 'r1x', 'r1y', 'r1z', 'r2x', 'r2y', 'r2z'])\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if FRAME_STEP != 0 and frame_idx % FRAME_STEP != 0:\n",
    "                frame_idx += 1\n",
    "                continue\n",
    "\n",
    "            cube_rvec, cube_tvec = estimator.process_frame(frame)\n",
    "            if cube_rvec is not None:\n",
    "                rmat, _ = cv2.Rodrigues(cube_rvec)\n",
    "                r6d = rotation_matrix_to_6d(rmat)\n",
    "\n",
    "                for i in range(AUG_PER_FRAME):\n",
    "                    aug_frame = adjust_brightness_contrast(frame)\n",
    "\n",
    "                    fname = f\"frame_{write_idx:04d}_v{i}.png\"\n",
    "                    image_path = os.path.join(IMAGES_FOLDER, fname)\n",
    "                    cv2.imwrite(image_path, aug_frame)\n",
    "\n",
    "                    writer.writerow([\n",
    "                        fname,\n",
    "                        float(cube_tvec[0][0]),\n",
    "                        float(cube_tvec[1][0]),\n",
    "                        float(cube_tvec[2][0]),\n",
    "                        *r6d\n",
    "                    ])\n",
    "\n",
    "                write_idx += 1  # Only increment write_idx per base frame\n",
    "\n",
    "            frame_idx += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "        now.append(time.time())\n",
    "        print(\"‚úÖ Finished reading video and writing labels.\")\n",
    "        print(f\"üïí Time took: {int(now[1]-now[0])}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62872760",
   "metadata": {},
   "source": [
    "LOAD THAT BIH AND SHUFFFLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f24f7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for split\n",
    "with open(LABELS_PATH, 'r') as f:\n",
    "    reader = list(csv.reader(f))\n",
    "    header = reader[0]\n",
    "    rows = reader[1:]\n",
    "\n",
    "# random.seed(42)\n",
    "random.shuffle(rows)\n",
    "\n",
    "total = len(rows)\n",
    "train_end = int(TRAIN_RATIO * total)\n",
    "val_end = train_end + int(VAL_RATIO * total)\n",
    "\n",
    "# First split by chunks, then shuffle each set to avoid overlap\n",
    "train = rows[:train_end]\n",
    "val = rows[train_end:val_end]\n",
    "test = rows[val_end:]\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(val)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8fcb8c",
   "metadata": {},
   "source": [
    "CREATE THE TRAIN TEST VAL FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25e750d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset split complete.\n",
      "Time took : 6s\n"
     ]
    }
   ],
   "source": [
    "# Create folders\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(BATCH_FOLDER, subset, 'images'), exist_ok=True)\n",
    "now = []\n",
    "now.append(time.time())\n",
    "# Copy images + write labels\n",
    "for subset_name, data in zip(['train', 'val', 'test'], [train, val, test]):\n",
    "    subset_folder = os.path.join(BATCH_FOLDER, subset_name)\n",
    "    csv_path = os.path.join(subset_folder, 'labels.csv')\n",
    "\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "            src_img = os.path.join(IMAGES_FOLDER, row[0])\n",
    "            dst_img = os.path.join(subset_folder, 'images', row[0])\n",
    "            shutil.copy(src_img, dst_img)\n",
    "now.append(time.time())\n",
    "print(\"‚úÖ Dataset split complete.\")\n",
    "print(f\"Time took : {int(now[1]-now[0])}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014766b2",
   "metadata": {},
   "source": [
    "WRITE IT OUTT (.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620456a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Metadata saved to dataset/batch7/metadata_7.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@764.820] global loadsave.cpp:268 findDecoder imread_('dataset/batch7/unsplit/images/frame_0000.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Removed the unsplit folder\n"
     ]
    }
   ],
   "source": [
    "# Write metadata\n",
    "sample_frame = cv2.imread(os.path.join(IMAGES_FOLDER, \"frame_0000.png\"))\n",
    "md_name = \"metadata_\"+str(BATCH_ID)+\".md\"\n",
    "metadata_path = os.path.join(BATCH_FOLDER, md_name)\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"# Batch {BATCH_ID} Metadata\\n\")\n",
    "    f.write(f\"- Date: {datetime.datetime.now().isoformat()}\\n\")\n",
    "    f.write(f\"- Total Frames: {len(rows)}\\n\")\n",
    "    f.write(f\"- Frame Step: {FRAME_STEP}\\n\")\n",
    "    f.write(f\"- Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\\n\")\n",
    "    f.write(f\"- Image Resolution: 1280 x 480\\n\")\n",
    "    f.write(f\"- ArUco-based 6DoF Pose Estimation\\n\")\n",
    "    f.write(f\"- Augmented frames per frame : {AUG_PER_FRAME}\\n\")\n",
    "    f.write(f\"- pose_normalization': Zhou 6D Rotation Representation\\n\")\n",
    "    f.write(f\"- Cube Size: {estimator.CUBE_SIZE if hasattr(estimator, 'CUBE_SIZE') else 0.08}m\\n\")\n",
    "\n",
    "print(f\"üìù Metadata saved to {metadata_path}\")\n",
    "shutil.rmtree(UNSPLIT_FOLDER)\n",
    "print(\"‚ùå Removed the unsplit folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0801200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Dataset metadata appended to CSV: dataset/dataset_info.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"dataset/dataset_info.csv\"\n",
    "os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "write_header = not os.path.exists(csv_path)\n",
    "\n",
    "\n",
    "\n",
    "csv_data = {\n",
    "    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'batch_id': BATCH_ID,\n",
    "    'total_frames': len(rows),\n",
    "    'frame_step': FRAME_STEP,\n",
    "    'train_count': len(train),\n",
    "    'val_count': len(val),\n",
    "    'test_count': len(test),\n",
    "    \"tr_val_test_ratio\": f\"{int(TRAIN_RATIO*100)}:{int(VAL_RATIO*100)}:{int(TEST_RATIO*100)}\",\n",
    "    'pose_method': \"ArUco-based 6DoF Pose Estimation\",\n",
    "    'pose_normalization': \"Zhou 6D Rotation Representation\"\n",
    "}\n",
    "\n",
    "with open(csv_path, 'a', newline='') as csvfile:\n",
    "    fieldnames = csv_data.keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(csv_data)\n",
    "\n",
    "print(f\"üìÑ Dataset metadata appended to CSV: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07968d27",
   "metadata": {},
   "source": [
    "INCRIMENT .. or is it increment? encriment? incriment? wait that's just the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86f7a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID updated to 8\n"
     ]
    }
   ],
   "source": [
    "gv['batch'] = batch + 1\n",
    "# Save the updated JSON back to the file\n",
    "with open(\"GlobVar.json\", \"w\") as file:\n",
    "    json.dump(gv, file, indent=4)\n",
    "print(f\"Batch ID updated to {gv['batch']}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
