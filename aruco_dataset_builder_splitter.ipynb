{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac499ea7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Updated: aruco_dataset_builder_splitter.py\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from aruco_box_pose_estimation import CubePoseEstimator\n",
    "from utility.rotation_utils import rotation_matrix_to_6d\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8004f16",
   "metadata": {},
   "source": [
    "PREREQS AND DECS AND INITIALS BLAAABLABLABLBLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ff1c8",
   "metadata": {
    "title": "Configuration"
   },
   "outputs": [],
   "source": [
    "with open(\"GlobVar.json\", \"r\") as file:\n",
    "    gv = json.load(file)\n",
    "batch = gv['batch']\n",
    "BATCH_ID = batch\n",
    "FRAME_STEP = 3  # Skip every N frames to reduce redundancy\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.2\n",
    "TRAIN_RATIO = 1 - VAL_RATIO - TEST_RATIO\n",
    "\n",
    "VIDEO_PATH = \"video/raw/ArUcoCom.avi\"\n",
    "BATCH_FOLDER = f\"dataset/batch{BATCH_ID}\"\n",
    "UNSPLIT_FOLDER = os.path.join(BATCH_FOLDER, \"unsplit\")\n",
    "IMAGES_FOLDER = os.path.join(UNSPLIT_FOLDER, \"images\")\n",
    "LABELS_PATH = os.path.join(UNSPLIT_FOLDER, \"labels.csv\")\n",
    "\n",
    "os.makedirs(IMAGES_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c861a0b",
   "metadata": {},
   "source": [
    "MAKE THE LABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58ad33",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading video and writing labels.\n",
      "Time took : 41s\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "estimator = CubePoseEstimator()\n",
    "frame_idx = 0\n",
    "write_idx = 0\n",
    "now = []\n",
    "now.append(time.time())\n",
    "with open(LABELS_PATH, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_name', 'x', 'y', 'z', 'r1x', 'r1y', 'r1z', 'r2x', 'r2y', 'r2z'])\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_idx % FRAME_STEP != 0:\n",
    "                frame_idx += 1\n",
    "                continue\n",
    "\n",
    "            cube_rvec, cube_tvec = estimator.process_frame(frame) #<-THIS BAD BOY IS THE ONE DOING THE HEAVY LIFTING IN ALL OF THIS TF\n",
    "            if cube_rvec is not None:\n",
    "                # Convert rotation vector to rotation matrix\n",
    "                rmat, _ = cv2.Rodrigues(cube_rvec)\n",
    "\n",
    "                # Convert rotation matrix to 6D (first two columns)\n",
    "                r6d = rotation_matrix_to_6d(rmat)  # returns np.ndarray with shape (6,)\n",
    "\n",
    "                # Save frame image\n",
    "                fname = f\"frame_{write_idx:04d}.png\"\n",
    "                image_path = os.path.join(IMAGES_FOLDER, fname)\n",
    "                cv2.imwrite(image_path, frame)\n",
    "\n",
    "                # Write translation + 6D rotation vector to CSV\n",
    "                writer.writerow([\n",
    "                    fname,\n",
    "                    float(cube_tvec[0][0]),\n",
    "                    float(cube_tvec[1][0]),\n",
    "                    float(cube_tvec[2][0]),\n",
    "                    *r6d\n",
    "                ])\n",
    "\n",
    "                write_idx += 1\n",
    "\n",
    "            frame_idx += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "        now.append(time.time())\n",
    "        print(\"Finished reading video and writing labels.\")\n",
    "        print(f\"Time took : {int(now[1]-now[0])}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62872760",
   "metadata": {},
   "source": [
    "LOAD THAT BIH AND SHUFFFLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f24f7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for split\n",
    "with open(LABELS_PATH, 'r') as f:\n",
    "    reader = list(csv.reader(f))\n",
    "    header = reader[0]\n",
    "    rows = reader[1:]\n",
    "\n",
    "# random.seed(42)\n",
    "random.shuffle(rows)\n",
    "\n",
    "total = len(rows)\n",
    "train_end = int(TRAIN_RATIO * total)\n",
    "val_end = train_end + int(VAL_RATIO * total)\n",
    "\n",
    "# First split by chunks, then shuffle each set to avoid overlap\n",
    "train = rows[:train_end]\n",
    "val = rows[train_end:val_end]\n",
    "test = rows[val_end:]\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(val)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8fcb8c",
   "metadata": {},
   "source": [
    "CREATE THE TRAIN TEST VAL FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c25e750d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset split complete.\n",
      "Time took : 1s\n"
     ]
    }
   ],
   "source": [
    "# Create folders\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(BATCH_FOLDER, subset, 'images'), exist_ok=True)\n",
    "now = []\n",
    "now.append(time.time())\n",
    "# Copy images + write labels\n",
    "for subset_name, data in zip(['train', 'val', 'test'], [train, val, test]):\n",
    "    subset_folder = os.path.join(BATCH_FOLDER, subset_name)\n",
    "    csv_path = os.path.join(subset_folder, 'labels.csv')\n",
    "\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "            src_img = os.path.join(IMAGES_FOLDER, row[0])\n",
    "            dst_img = os.path.join(subset_folder, 'images', row[0])\n",
    "            shutil.copy(src_img, dst_img)\n",
    "now.append(time.time())\n",
    "print(\"âœ… Dataset split complete.\")\n",
    "print(f\"Time took : {int(now[1]-now[0])}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014766b2",
   "metadata": {},
   "source": [
    "WRITE IT OUTT (.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "620456a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Metadata saved to dataset/batch5/metadata_5.md\n",
      "âŒ Removed the unsplit folder\n"
     ]
    }
   ],
   "source": [
    "# Write metadata\n",
    "sample_frame = cv2.imread(os.path.join(IMAGES_FOLDER, \"frame_0000.png\"))\n",
    "md_name = \"metadata_\"+str(BATCH_ID)+\".md\"\n",
    "metadata_path = os.path.join(BATCH_FOLDER, md_name)\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"# Batch {BATCH_ID} Metadata\\n\")\n",
    "    f.write(f\"- Date: {datetime.now().isoformat()}\\n\")\n",
    "    f.write(f\"- Total Frames: {len(rows)}\\n\")\n",
    "    f.write(f\"- Frame Step: {FRAME_STEP}\\n\")\n",
    "    f.write(f\"- Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\\n\")\n",
    "    f.write(f\"- Image Resolution: {sample_frame.shape[1]}x{sample_frame.shape[0]}\\n\")\n",
    "    f.write(f\"- ArUco-based 6DoF Pose Estimation\\n\")\n",
    "    f.write(f\"- Pose Normalization: Euler angles divided by 360\\n\")\n",
    "    f.write(f\"- Cube Size: {estimator.CUBE_SIZE if hasattr(estimator, 'CUBE_SIZE') else 0.08}m\\n\")\n",
    "\n",
    "print(f\"ðŸ“ Metadata saved to {metadata_path}\")\n",
    "shutil.rmtree(UNSPLIT_FOLDER)\n",
    "print(\"âŒ Removed the unsplit folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07968d27",
   "metadata": {},
   "source": [
    "INCRIMENT .. or is it increment? encriment? incriment? wait that's just the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d86f7a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID updated to 6\n"
     ]
    }
   ],
   "source": [
    "gv['batch'] = batch + 1\n",
    "# Save the updated JSON back to the file\n",
    "with open(\"GlobVar.json\", \"w\") as file:\n",
    "    json.dump(gv, file, indent=4)\n",
    "print(f\"Batch ID updated to {gv['batch']}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
