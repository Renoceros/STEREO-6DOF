{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a5fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# development_calibration.ipynb\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import utility.stereo_utils as su\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d42845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CALIBRATION SETTINGS ======\n",
    "CHESSBOARD_SIZE = (8, 5)  # (columns, rows) - INTERNAL corners\n",
    "SQUARE_SIZE = 0.025       # 2.5cm squares\n",
    "CALIB_IMAGES_DIR = \"calibration_images/\"\n",
    "OUTPUT_JSON = \"development_calibration.json\"\n",
    "\n",
    "# ====== PATHS ======\n",
    "os.makedirs(CALIB_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(\"development/steps\", exist_ok=True)\n",
    "\n",
    "# ====== OBJECT POINTS ======\n",
    "objp = np.zeros((CHESSBOARD_SIZE[0] * CHESSBOARD_SIZE[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESSBOARD_SIZE[0], 0:CHESSBOARD_SIZE[1]].T.reshape(-1, 2)\n",
    "objp *= SQUARE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca49333",
   "metadata": {},
   "source": [
    "====== MAIN CALIBRATION ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4085f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_monocular(image_paths, side_name):\n",
    "    objpoints, imgpoints = [], []\n",
    "    img_shape = None\n",
    "    \n",
    "    for idx, fname in enumerate(image_paths):\n",
    "        img = cv2.imread(fname)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Skipping invalid image: {fname}\")\n",
    "            continue\n",
    "            \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Try different detection methods\n",
    "        ret, corners = cv2.findChessboardCornersSB(\n",
    "            gray, CHESSBOARD_SIZE, \n",
    "            flags=cv2.CALIB_CB_NORMALIZE_IMAGE|cv2.CALIB_CB_EXHAUSTIVE\n",
    "        )\n",
    "        \n",
    "        if not ret:  # Fallback to standard method\n",
    "            ret, corners = cv2.findChessboardCorners(\n",
    "                gray, CHESSBOARD_SIZE,\n",
    "                flags=cv2.CALIB_CB_ADAPTIVE_THRESH\n",
    "            )\n",
    "        \n",
    "        if ret:\n",
    "            corners = cv2.cornerSubPix(\n",
    "                gray, corners, (11,11), (-1,-1),\n",
    "                criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.0001)\n",
    "            )\n",
    "            \n",
    "            if img_shape is None:\n",
    "                img_shape = gray.shape[::-1]\n",
    "                \n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            \n",
    "            # Visual verification\n",
    "            vis = cv2.drawChessboardCorners(img.copy(), CHESSBOARD_SIZE, corners, ret)\n",
    "            cv2.imwrite(f\"development/steps/{side_name.lower()}_corners_{idx:02d}.png\", vis)\n",
    "        else:\n",
    "            print(f\"❌ Chessboard not found in {os.path.basename(fname)}\")\n",
    "    \n",
    "    if not objpoints:\n",
    "        raise ValueError(f\"No chessboards detected in {side_name} images!\")\n",
    "    \n",
    "    # Simplified calibration\n",
    "    ret, mtx, dist, _, _ = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, img_shape, None, None\n",
    "    )\n",
    "    \n",
    "    print(f\"{side_name} Calibration Error: {ret:.3f} pixels\")\n",
    "    return mtx, dist, objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1872ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "left_images = sorted(glob.glob(\"development/left/*.jpg\"))\n",
    "right_images = sorted(glob.glob(\"development/right/*.jpg\"))\n",
    "stereo_images = sorted(glob.glob(\"development/together/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1146da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 left images and 35 right images\n",
      "✓ development/left\\left_00.jpg - (480, 640, 3)\n",
      "✓ development/left\\left_01.jpg - (480, 640, 3)\n",
      "✓ development/left\\left_02.jpg - (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Add this before calibration\n",
    "print(f\"Found {len(left_images)} left images and {len(right_images)} right images\")\n",
    "for img_path in left_images[:3]:  # Check first 3 images\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ Failed to load: {img_path}\")\n",
    "    else:\n",
    "        print(f\"✓ {img_path} - {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d33879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MONOCULAR CALIBRATION ===\n",
      "LEFT Calibration Error: 0.234 pixels\n",
      "RIGHT Calibration Error: 0.324 pixels\n"
     ]
    }
   ],
   "source": [
    "# Monocular Calibration\n",
    "print(\"=== MONOCULAR CALIBRATION ===\")\n",
    "mtxL, distL, objL, imgL = calibrate_monocular(left_images, \"LEFT\")\n",
    "mtxR, distR, objR, imgR = calibrate_monocular(right_images, \"RIGHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750b64b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUNNING STEREO CALIBRATION ===\n",
      "Found 24 valid stereo pairs\n",
      "\n",
      "=== RESULTS ===\n",
      "Calibration Error: 0.353 pixels (should be < 0.5)\n",
      "Translation (Baseline): X=-0.1117m, Y=0.0059m, Z=-0.0693m\n",
      "Baseline Norm: 0.1316m (expected: 0.120m)\n",
      "\n",
      "Translation Vector Analysis:\n",
      "X (left-right): -0.1117m (should be ~0.12)\n",
      "Y (vertical): 0.0059m (should be ~0)\n",
      "Z (depth): -0.0693m (should be ~0)\n"
     ]
    }
   ],
   "source": [
    "# ===== PROPER STEREO CALIBRATION =====\n",
    "print(\"\\n=== RUNNING STEREO CALIBRATION ===\")\n",
    "\n",
    "# Load synchronized stereo pairs\n",
    "stereo_images = sorted(glob.glob(\"development/together/*.jpg\"))\n",
    "objpoints_stereo = []\n",
    "imgpoints_left = []\n",
    "imgpoints_right = []\n",
    "\n",
    "for idx, fname in enumerate(stereo_images):\n",
    "    img = cv2.imread(fname)\n",
    "    h, w = img.shape[:2]\n",
    "    left = img[:, :w//2]\n",
    "    right = img[:, w//2:]\n",
    "    \n",
    "    grayL = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "    grayR = cv2.cvtColor(right, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect corners in BOTH images\n",
    "    retL, cornersL = cv2.findChessboardCornersSB(grayL, (8,5), None)\n",
    "    retR, cornersR = cv2.findChessboardCornersSB(grayR, (8,5), None)\n",
    "    \n",
    "    if retL and retR:\n",
    "        # Refine corners\n",
    "        cornersL = cv2.cornerSubPix(grayL, cornersL, (11,11), (-1,-1),\n",
    "                                   criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "        cornersR = cv2.cornerSubPix(grayR, cornersR, (11,11), (-1,-1),\n",
    "                                    criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "        \n",
    "        objpoints_stereo.append(objp)\n",
    "        imgpoints_left.append(cornersL)\n",
    "        imgpoints_right.append(cornersR)\n",
    "        \n",
    "        # Visualization\n",
    "        vis = np.hstack([\n",
    "            cv2.drawChessboardCorners(left.copy(), (8,5), cornersL, retL),\n",
    "            cv2.drawChessboardCorners(right.copy(), (8,5), cornersR, retR)\n",
    "        ])\n",
    "        cv2.imwrite(f\"development/steps/stereo_pair_{idx:02d}.png\", vis)\n",
    "\n",
    "print(f\"Found {len(objpoints_stereo)} valid stereo pairs\")\n",
    "\n",
    "\n",
    "flags = cv2.CALIB_FIX_INTRINSIC  # Preserves mtxL, mtxR, distL, distR\n",
    "\n",
    "ret, mtxL, distL, mtxR, distR, R, T, E, F = cv2.stereoCalibrate(\n",
    "    objpoints_stereo,\n",
    "    imgpoints_left,    # Left camera points\n",
    "    imgpoints_right,   # Right camera points\n",
    "    mtxL, distL,       # From left monocular calibration\n",
    "    mtxR, distR,       # From right monocular calibration\n",
    "    grayL.shape[::-1], # Image dimensions\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5),\n",
    "    flags=flags        # Critical fix!\n",
    ")\n",
    "\n",
    "print(\"\\n=== RESULTS ===\")\n",
    "print(f\"Calibration Error: {ret:.3f} pixels (should be < 0.5)\")\n",
    "print(f\"Translation (Baseline): X={T[0][0]:.4f}m, Y={T[1][0]:.4f}m, Z={T[2][0]:.4f}m\")\n",
    "print(f\"Baseline Norm: {np.linalg.norm(T):.4f}m (expected: 0.120m)\")\n",
    "\n",
    "# Verify T direction makes sense\n",
    "print(\"\\nTranslation Vector Analysis:\")\n",
    "print(f\"X (left-right): {T[0][0]:.4f}m (should be ~0.12)\")\n",
    "print(f\"Y (vertical): {T[1][0]:.4f}m (should be ~0)\")\n",
    "print(f\"Z (depth): {T[2][0]:.4f}m (should be ~0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38fd82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectification\n",
    "R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(\n",
    "    mtxL, distL, mtxR, distR,\n",
    "    grayL.shape[::-1], R, T,\n",
    "    alpha=0.9,  # Preserve 90% of image\n",
    "    flags=cv2.CALIB_ZERO_DISPARITY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55b50ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calibration saved to development_calibration.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "calib_data = {\n",
    "    \"mtx_left\": mtxL.tolist(),\n",
    "    \"dist_left\": distL.tolist(),\n",
    "    \"mtx_right\": mtxR.tolist(),\n",
    "    \"dist_right\": distR.tolist(),\n",
    "    \"R\": R.tolist(),\n",
    "    \"T\": T.tolist(),\n",
    "    \"E\": E.tolist(),\n",
    "    \"F\": F.tolist(),\n",
    "    \"R1\": R1.tolist(),\n",
    "    \"R2\": R2.tolist(),\n",
    "    \"P1\": P1.tolist(),\n",
    "    \"P2\": P2.tolist(),\n",
    "    \"Q\": Q.tolist()\n",
    "}\n",
    "\n",
    "with open(OUTPUT_JSON, 'w') as f:\n",
    "    json.dump(calib_data, f, indent=4)\n",
    "\n",
    "print(f\"\\nCalibration saved to {OUTPUT_JSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca719b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CALIBRATION VALIDATION ===\n",
      "Left Camera Focal Length: 655.7, 654.2\n",
      "Right Camera Focal Length: 532.2, 531.3\n",
      "Baseline Distance: 0.132 meters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load calibration\n",
    "with open(\"development_calibration.json\") as f:\n",
    "    calib = json.load(f)\n",
    "\n",
    "# Verify parameters\n",
    "print(\"=== CALIBRATION VALIDATION ===\")\n",
    "print(f\"Left Camera Focal Length: {calib['mtx_left'][0][0]:.1f}, {calib['mtx_left'][1][1]:.1f}\")\n",
    "print(f\"Right Camera Focal Length: {calib['mtx_right'][0][0]:.1f}, {calib['mtx_right'][1][1]:.1f}\")\n",
    "print(f\"Baseline Distance: {np.linalg.norm(calib['T']):.3f} meters\")\n",
    "\n",
    "# Test undistortion\n",
    "test_img = cv2.imread(\"development/together/together_75.jpg\")\n",
    "left, right = su.Split_Stereo_Frame(test_img)\n",
    "\n",
    "left_undist = cv2.undistort(left, np.array(calib['mtx_left']), np.array(calib['dist_left']))\n",
    "right_undist = cv2.undistort(right, np.array(calib['mtx_right']), np.array(calib['dist_right']))\n",
    "\n",
    "cv2.imwrite(\"validation_left.jpg\", np.hstack((left, left_undist)))\n",
    "cv2.imwrite(\"validation_right.jpg\", np.hstack((right, right_undist)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d448c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated Baseline: 0.132m (Expected: 0.120m)\n",
      "Discrepancy: 1.2cm\n",
      "\n",
      "Translation Vector Components:\n",
      "X: -0.1117m (should match left/right direction)\n",
      "Y: 0.0059m (typically small)\n",
      "Z: -0.0693m (typically near zero)\n"
     ]
    }
   ],
   "source": [
    "# Current reported baseline\n",
    "T = np.array(calib['T'])\n",
    "calculated_baseline = np.linalg.norm(T)\n",
    "print(f\"Calibrated Baseline: {calculated_baseline:.3f}m (Expected: 0.120m)\")\n",
    "print(f\"Discrepancy: {abs(calculated_baseline-0.12)*100:.1f}cm\")\n",
    "\n",
    "# Check translation vector direction\n",
    "print(\"\\nTranslation Vector Components:\")\n",
    "print(f\"X: {T[0][0]:.4f}m (should match left/right direction)\")\n",
    "print(f\"Y: {T[1][0]:.4f}m (typically small)\")\n",
    "print(f\"Z: {T[2][0]:.4f}m (typically near zero)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
