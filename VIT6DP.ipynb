{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592a6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIT6D.ipynb refactored for Minty (Linux Mint)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d4ae2",
   "metadata": {},
   "source": [
    "PREREQUISITES AND DECLARATIONS AND YADA YADA YADA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e5b772",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "with open(\"GlobVar.json\", \"r\") as file:\n",
    "    gv = json.load(file)\n",
    "mod_id = gv['mod_id']\n",
    "# Constants and environment setup\n",
    "BATCH_ID = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "IMG_SIZE = 224  # Required input size for ViT\n",
    "\n",
    "# Paths assume Linux-style forward slashes\n",
    "BASE_DIR = os.path.expanduser(\"~/SKRIPSI/SCRIPTS\")  # Refactor path to be absolute\n",
    "DATASET_DIR = os.path.join(BASE_DIR, f\"dataset/batch{BATCH_ID}\")\n",
    "MODEL_SAVE_PATH = os.path.join(BASE_DIR, f\"model/ViT6DP_batch{BATCH_ID}.{mod_id}.pth\")\n",
    "\n",
    "# Use CUDA if available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6f4d3a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_csv, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = pd.read_csv(label_csv)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['image_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(row[1:].values.astype('float32'))  # x, y, z, pitch, roll, yaw\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10edf29",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a43fbf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_dataloader(split):\n",
    "    image_dir = os.path.join(DATASET_DIR, split, 'images')\n",
    "    label_csv = os.path.join(DATASET_DIR, split, 'labels.csv')\n",
    "    dataset = PoseDataset(image_dir, label_csv, transform)\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=(split == 'train'))\n",
    "\n",
    "train_loader = get_dataloader('train')\n",
    "val_loader = get_dataloader('val')\n",
    "test_loader = get_dataloader('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fec07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Translation stat:{'min': tensor([-0.2061, -0.1280,  0.0981]), 'max': tensor([0.2004, 0.1593, 0.6350]), 'mean': tensor([-0.0092,  0.0355,  0.3953]), 'std': tensor([0.0525, 0.0431, 0.0779])}      |       Train Rotation stat: {'min': tensor([-1.0000, -1.0000, -0.9999, -0.9999, -0.9490, -0.9959]), 'max': tensor([0.9999, 1.0000, 0.9997, 0.9986, 0.9766, 0.9765]), 'mean': tensor([ 0.1674, -0.0010, -0.0022, -0.1675, -0.0266,  0.0288]), 'std': tensor([0.7254, 0.5623, 0.5539, 0.6985, 0.3727, 0.4095])}\n",
      "Validation Translation stat:{'min': tensor([-0.1940, -0.1262,  0.1145]), 'max': tensor([0.1277, 0.1506, 0.6368]), 'mean': tensor([-0.0093,  0.0361,  0.3949]), 'std': tensor([0.0512, 0.0447, 0.0856])}     |       Validation Rotation stat: {'min': tensor([-0.9989, -0.9985, -0.9958, -0.9977, -0.8561, -0.9641]), 'max': tensor([0.9998, 0.9985, 0.9947, 0.9969, 0.9158, 0.9269]), 'mean': tensor([ 0.0725, -0.0196,  0.0007, -0.0803,  0.0033, -0.0223]), 'std': tensor([0.7408, 0.5672, 0.5597, 0.7074, 0.3702, 0.4183])}\n",
      "Test Translation stat:{'min': tensor([-0.1916, -0.1158,  0.0255]), 'max': tensor([0.1636, 0.1489, 0.6420]), 'mean': tensor([-0.0075,  0.0363,  0.4025]), 'std': tensor([0.0495, 0.0399, 0.0796])}      |       Test Rotation stat: {'min': tensor([-0.9993, -0.9920, -0.9992, -0.9993, -0.8793, -0.9863]), 'max': tensor([0.9973, 0.9992, 0.9954, 1.0000, 0.8419, 0.9166]), 'mean': tensor([ 0.1506,  0.0452,  0.0329, -0.1485, -0.0258,  0.0225]), 'std': tensor([0.7269, 0.5632, 0.5768, 0.7064, 0.3415, 0.4016])}\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_stats(loader):\n",
    "    all_labels = []\n",
    "    for _, labels in loader:\n",
    "        all_labels.append(labels)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    # Translation stats (x,y,z)\n",
    "    trans_stats = {\n",
    "        'min': all_labels[:, :3].min(dim=0)[0],\n",
    "        'max': all_labels[:, :3].max(dim=0)[0],\n",
    "        'mean': all_labels[:, :3].mean(dim=0),\n",
    "        'std': all_labels[:, :3].std(dim=0)\n",
    "    }\n",
    "    \n",
    "    # Rotation stats (pitch, roll, yaw)\n",
    "    rot_stats = {\n",
    "        'min': all_labels[:, 3:].min(dim=0)[0],\n",
    "        'max': all_labels[:, 3:].max(dim=0)[0],\n",
    "        'mean': all_labels[:, 3:].mean(dim=0),\n",
    "        'std': all_labels[:, 3:].std(dim=0)\n",
    "    }\n",
    "    \n",
    "    return trans_stats, rot_stats\n",
    "\n",
    "# Get stats for each dataset split\n",
    "train_trans_stats, train_rot_stats = get_dataset_stats(train_loader)\n",
    "val_trans_stats, val_rot_stats = get_dataset_stats(val_loader)\n",
    "test_trans_stats, test_rot_stats = get_dataset_stats(test_loader)\n",
    "print(f\"Train Translation stat:{train_trans_stats}      |       Train Rotation stat: {train_rot_stats}\")\n",
    "print(f\"Validation Translation stat:{val_trans_stats}     |       Validation Rotation stat: {val_rot_stats}\")\n",
    "print(f\"Test Translation stat:{test_trans_stats}      |       Test Rotation stat: {test_rot_stats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4e2da8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ViT6DP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.backbone.head = nn.Sequential(\n",
    "            nn.Linear(self.backbone.head.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 9)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af30195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(pred, target):\n",
    "    pred_trans, pred_rot = pred[:, :3], pred[:, 3:]\n",
    "    target_trans, target_rot = target[:, :3], target[:, 3:]\n",
    "\n",
    "    trans_rmse = torch.sqrt(nn.MSELoss()(pred_trans, target_trans))\n",
    "    rot_rmse = torch.sqrt(nn.MSELoss()(pred_rot, target_rot))\n",
    "\n",
    "    return trans_rmse.item(), rot_rmse.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559f8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(pred, target, alpha=1.0, beta=1.0):\n",
    "    pred_trans, pred_rot = pred[:, :3], pred[:, 3:]\n",
    "    target_trans, target_rot = target[:, :3], target[:, 3:]\n",
    "\n",
    "    trans_loss = nn.MSELoss()(pred_trans, target_trans)\n",
    "    rot_loss = nn.MSELoss()(pred_rot, target_rot)\n",
    "\n",
    "    return alpha * trans_loss + beta * rot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f021f0ea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = ViT6DP().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818da2e",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e01d6f41",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train(validate=True):\n",
    "    now = [time.time()]\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"\\n\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)  # shape: [B, 9] -> [tx, ty, tz, r1...r6]\n",
    "\n",
    "            outputs = model(images)  # no normalize_pose anymore\n",
    "\n",
    "            loss = combined_loss(outputs, labels, alpha=1.0, beta=1.0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        now.append(time.time())\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Time per epoch {epoch + 1}: {int(now[epoch + 1] - now[epoch])}s\")\n",
    "\n",
    "        if validate:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            total_trans_rmse, total_rot_rmse = 0.0, 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images = images.to(DEVICE)\n",
    "                    labels = labels.to(DEVICE)\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    loss = combined_loss(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    trans_rmse, rot_rmse = compute_rmse(outputs, labels)\n",
    "                    total_trans_rmse += trans_rmse\n",
    "                    total_rot_rmse += rot_rmse\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"RMSE - Translation: {total_trans_rmse / len(val_loader):.4f}, \"\n",
    "                  f\"Rotation: {total_rot_rmse / len(val_loader):.4f}\")\n",
    "        else:\n",
    "            print(\"Skipping validation for this epoch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bafc972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.3623\n",
      "Time per epoch 1: 32s\n",
      "Val Loss: 0.3352\n",
      "RMSE - Translation: 0.0669, Rotation: 0.5745\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 0.3202\n",
      "Time per epoch 2: 35s\n",
      "Val Loss: 0.3539\n",
      "RMSE - Translation: 0.0645, Rotation: 0.5909\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.3238\n",
      "Time per epoch 3: 35s\n",
      "Val Loss: 0.3192\n",
      "RMSE - Translation: 0.0650, Rotation: 0.5597\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.2914\n",
      "Time per epoch 4: 35s\n",
      "Val Loss: 0.2718\n",
      "RMSE - Translation: 0.0632, Rotation: 0.5169\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.2413\n",
      "Time per epoch 5: 35s\n",
      "Val Loss: 0.2496\n",
      "RMSE - Translation: 0.0743, Rotation: 0.4938\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.1875\n",
      "Time per epoch 6: 35s\n",
      "Val Loss: 0.2627\n",
      "RMSE - Translation: 0.0600, Rotation: 0.5054\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.1269\n",
      "Time per epoch 7: 35s\n",
      "Val Loss: 0.2155\n",
      "RMSE - Translation: 0.0558, Rotation: 0.4576\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.0907\n",
      "Time per epoch 8: 35s\n",
      "Val Loss: 0.1912\n",
      "RMSE - Translation: 0.0564, Rotation: 0.4317\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 0.0575\n",
      "Time per epoch 9: 35s\n",
      "Val Loss: 0.2026\n",
      "RMSE - Translation: 0.0506, Rotation: 0.4429\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 0.0369\n",
      "Time per epoch 10: 35s\n",
      "Val Loss: 0.2086\n",
      "RMSE - Translation: 0.0480, Rotation: 0.4505\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 0.0257\n",
      "Time per epoch 11: 35s\n",
      "Val Loss: 0.2025\n",
      "RMSE - Translation: 0.0522, Rotation: 0.4410\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 0.0153\n",
      "Time per epoch 12: 35s\n",
      "Val Loss: 0.1918\n",
      "RMSE - Translation: 0.0475, Rotation: 0.4311\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Loss: 0.0088\n",
      "Time per epoch 13: 35s\n",
      "Val Loss: 0.1992\n",
      "RMSE - Translation: 0.0467, Rotation: 0.4383\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Loss: 0.0054\n",
      "Time per epoch 14: 35s\n",
      "Val Loss: 0.2088\n",
      "RMSE - Translation: 0.0490, Rotation: 0.4465\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Loss: 0.0038\n",
      "Time per epoch 15: 35s\n",
      "Val Loss: 0.1970\n",
      "RMSE - Translation: 0.0459, Rotation: 0.4366\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Train Loss: 0.0027\n",
      "Time per epoch 16: 35s\n",
      "Val Loss: 0.1924\n",
      "RMSE - Translation: 0.0453, Rotation: 0.4306\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Train Loss: 0.0020\n",
      "Time per epoch 17: 35s\n",
      "Val Loss: 0.1958\n",
      "RMSE - Translation: 0.0464, Rotation: 0.4349\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 0.0024\n",
      "Time per epoch 18: 35s\n",
      "Val Loss: 0.1894\n",
      "RMSE - Translation: 0.0464, Rotation: 0.4275\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Train Loss: 0.0017\n",
      "Time per epoch 19: 35s\n",
      "Val Loss: 0.1927\n",
      "RMSE - Translation: 0.0456, Rotation: 0.4314\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.0013\n",
      "Time per epoch 20: 35s\n",
      "Val Loss: 0.1960\n",
      "RMSE - Translation: 0.0453, Rotation: 0.4351\n"
     ]
    }
   ],
   "source": [
    "train(validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd1a361",
   "metadata": {},
   "source": [
    "SAVE + INCREMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0aa676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "# Increment\n",
    "mod_id += 1\n",
    "gv['mod_id'] = mod_id\n",
    "# Save the updated JSON back to the file\n",
    "with open(\"GlobVar.json\", \"w\") as file:\n",
    "    json.dump(gv, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a7917",
   "metadata": {},
   "source": [
    "TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ac53c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_model(model_path):\n",
    "    model = ViT6DP().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    test_total_loss = 0.0\n",
    "    test_total_trans_rmse, test_total_rot_rmse = 0.0, 0.0\n",
    "    preds, gts = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = combined_loss(outputs, labels)\n",
    "            test_total_loss += loss.item()\n",
    "\n",
    "            trans_rmse, rot_rmse = compute_rmse(outputs, labels)\n",
    "            test_total_trans_rmse += trans_rmse\n",
    "            test_total_rot_rmse += rot_rmse\n",
    "\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "            gts.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_avg_loss = test_total_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {test_avg_loss:.4f}\")\n",
    "    print(f\"Test RMSE - Translation: {test_total_trans_rmse / len(test_loader):.4f}, \"\n",
    "          f\"Rotation: {test_total_rot_rmse / len(test_loader):.4f}\")\n",
    "\n",
    "    return preds, gts, test_avg_loss, test_total_trans_rmse, test_total_rot_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d947127",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1793\n",
      "Test RMSE - Translation: 0.0452, Rotation: 0.4147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, ground_truths, test_avg_loss, test_total_trans_rmse, test_total_rot_rmse = test_model(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e6f140",
   "metadata": {},
   "source": [
    "VALIDATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c1ff78",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def validate_model(model_path):\n",
    "    model = ViT6DP().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    val_total_loss = 0.0\n",
    "    val_total_trans_rmse, val_total_rot_rmse = 0.0, 0.0\n",
    "    preds, gts = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = combined_loss(outputs, labels)\n",
    "            val_total_loss += loss.item()\n",
    "\n",
    "            trans_rmse, rot_rmse = compute_rmse(outputs, labels)\n",
    "            val_total_trans_rmse += trans_rmse\n",
    "            val_total_rot_rmse += rot_rmse\n",
    "\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "            gts.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_avg_loss = val_total_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {val_avg_loss:.4f}\")\n",
    "    print(f\"Validation RMSE - Translation: {val_total_trans_rmse / len(val_loader):.4f}, \"\n",
    "          f\"Rotation: {val_total_rot_rmse / len(val_loader):.4f}\")\n",
    "\n",
    "    return preds, gts, val_avg_loss, val_total_trans_rmse, val_total_rot_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db70a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1960\n",
      "Validation RMSE - Translation: 0.0453, Rotation: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_predictions, val_ground_truths, val_avg_loss, val_total_trans_rmse, val_total_rot_rmse = validate_model(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6003a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c71dd9",
   "metadata": {},
   "source": [
    "CALCULATIONS AND SUCH (ALSO OUTPUTTING TO MD AND CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f71ec21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_to_rotation_matrix(r1, r2):\n",
    "    \"\"\"Convert orthogonalized r1 and r2 vectors into a rotation matrix.\"\"\"\n",
    "    r1 = r1 / np.linalg.norm(r1)\n",
    "    r2 = r2 / np.linalg.norm(r2)\n",
    "    r3 = np.cross(r1, r2)\n",
    "    return np.stack([r1, r2, r3], axis=1)\n",
    "\n",
    "def calculate_translation_rmse(preds, gts):\n",
    "    \"\"\"Euclidean distance between predicted and GT translations (in meters).\"\"\"\n",
    "    errors = np.linalg.norm(preds - gts, axis=1)  # Shape: [N]\n",
    "    rmse = np.sqrt(np.mean(errors**2))\n",
    "    return rmse * 1000  # Convert to mm\n",
    "\n",
    "def calculate_rotation_rmse(preds_r1r2, gts_r1r2):\n",
    "    \"\"\"Angular difference (in degrees) between predicted and GT rotation matrices.\"\"\"\n",
    "    angles = []\n",
    "    for pred, gt in zip(preds_r1r2, gts_r1r2):\n",
    "        R_pred = vectors_to_rotation_matrix(pred[:3], pred[3:])\n",
    "        R_gt = vectors_to_rotation_matrix(gt[:3], gt[3:])\n",
    "        R_diff = R_pred.T @ R_gt\n",
    "        angle = np.arccos(np.clip((np.trace(R_diff) - 1) / 2.0, -1.0, 1.0))\n",
    "        angles.append(np.degrees(angle))\n",
    "    return np.sqrt(np.mean(np.array(angles)**2))  # RMSE in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b086a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_trans_accuracy, val_rot_accuracy = val_total_trans_rmse / len(val_loader),  val_total_rot_rmse / len(val_loader)\n",
    "test_trans_accuracy, test_rot_accuracy = test_total_trans_rmse / len(test_loader),  test_total_rot_rmse / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab98dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rot_mag_min = train_rot_stats['min'].norm().item()\n",
    "train_rot_mag_max = train_rot_stats['max'].norm().item()\n",
    "val_rot_mag_min = val_rot_stats['min'].norm().mean().item()\n",
    "val_rot_mag_max = val_rot_stats['max'].norm().mean().item()\n",
    "test_rot_mag_min = test_rot_stats['min'].norm().mean().item()\n",
    "test_rot_mag_max = test_rot_stats['max'].norm().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61826ebd",
   "metadata": {},
   "source": [
    "WRITE TO MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f2d42f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation report saved to: /home/moreno/SKRIPSI/SCRIPTS/model/ViT6DP_EVAL_batch1.1.md\n"
     ]
    }
   ],
   "source": [
    "eval_content = f\"\"\"# Evaluation Results - Batch {BATCH_ID}\n",
    "\n",
    "## Training Configuration\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "- Epochs: {NUM_EPOCHS}\n",
    "- Learning Rate: {LEARNING_RATE}\n",
    "- Image Size: {IMG_SIZE}\n",
    "- Device: {DEVICE}\n",
    "- Optimizer : Adam\n",
    "\n",
    "## Model Architecture\n",
    "- Backbone: ViT Base Patch16 224\n",
    "- Head: Linear(768->512->6)\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "### Validation Set\n",
    "- Average Loss: {val_avg_loss:.4f}\n",
    "- Translation RMSE: {val_total_trans_rmse / len(val_loader):.4f}\n",
    "- Translation Accuracy: {val_trans_accuracy:.2f} cm\n",
    "- Rotation RMSE: {val_total_rot_rmse / len(val_loader):.4f}\n",
    "- Rotation Accuracy: {val_rot_accuracy:.2f}°\n",
    "\n",
    "### Test Set\n",
    "- Average Loss: {test_avg_loss:.4f}\n",
    "- Translation RMSE: {test_total_trans_rmse / len(test_loader):.4f}\n",
    "- Translation Accuracy: {test_trans_accuracy:.2f} cm\n",
    "- Rotation RMSE: {test_total_rot_rmse / len(test_loader):.4f}\n",
    "- Rotation Accuracy: {test_rot_accuracy:.2f}°\n",
    "\n",
    "## Dataset Statistics\n",
    "### Training Set\n",
    "- Translation range: [{train_trans_stats['min'].mean():.2f}, {train_trans_stats['max'].mean():.2f}] m\n",
    "- Rotation magnitude range: [{train_rot_mag_min:.2f}, {train_rot_mag_max:.2f}]\n",
    "\n",
    "### Validation Set\n",
    "- Translation range: [{val_trans_stats['min'].mean():.2f}, {val_trans_stats['max'].mean():.2f}] m\n",
    "- Rotation magnitude range: [{val_rot_mag_min:.2f}, {val_rot_mag_max:.2f}]\n",
    "\n",
    "### Test Set\n",
    "- Translation range: [{test_trans_stats['min'].mean():.2f}, {test_trans_stats['max'].mean():.2f}] m\n",
    "- Rotation magnitude range: [{test_rot_mag_min:.2f}, {test_rot_mag_max:.2f}]\n",
    "\n",
    "## File Locations\n",
    "- Dataset Directory: {DATASET_DIR}\n",
    "- Model Save Path: {MODEL_SAVE_PATH}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "eval_path = os.path.join(BASE_DIR, f\"model/ViT6DP_EVAL_batch{BATCH_ID}.{mod_id-1}.md\")\n",
    "with open(eval_path, 'w') as f:\n",
    "    f.write(eval_content)\n",
    "    \n",
    "print(f\"Evaluation report saved to: {eval_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f43d3d",
   "metadata": {},
   "source": [
    "WRITE TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e89dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results appended to CSV: /home/moreno/SKRIPSI/SCRIPTS/model/eval_results.csv\n"
     ]
    }
   ],
   "source": [
    "# First, define the CSV file path\n",
    "csv_path = os.path.join(BASE_DIR, \"model/eval_results.csv\")\n",
    "\n",
    "# Check if CSV exists to determine if we need to write headers\n",
    "write_header = not os.path.exists(csv_path)\n",
    "\n",
    "\n",
    "csv_data = {\n",
    "    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset_id': BATCH_ID,\n",
    "    'model_id': mod_id,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'val_loss': val_avg_loss,\n",
    "    'val_trans_rmse': val_total_trans_rmse / len(val_loader),\n",
    "    'val_trans_acc_cm': val_trans_accuracy,\n",
    "    'val_rot_rmse': val_total_rot_rmse / len(val_loader),\n",
    "    'val_rot_acc_deg': val_rot_accuracy,\n",
    "    'test_loss': test_avg_loss,\n",
    "    'test_trans_rmse': test_total_trans_rmse / len(test_loader),\n",
    "    'test_trans_acc_cm': test_trans_accuracy,\n",
    "    'test_rot_rmse': test_total_rot_rmse / len(test_loader),\n",
    "    'test_rot_acc_deg': test_rot_accuracy,\n",
    "    'train_trans_min': train_trans_stats['min'].mean().item(),\n",
    "    'train_trans_max': train_trans_stats['max'].mean().item(),\n",
    "    'train_rot_min': (train_rot_stats['min'].mean()*360).item(),\n",
    "    'train_rot_max': (train_rot_stats['max'].mean()*360).item(),\n",
    "    'val_rot_min': val_rot_mag_min,\n",
    "    'val_rot_max': val_rot_mag_max,\n",
    "    'test_rot_min': test_rot_mag_min,\n",
    "    'test_rot_max': test_rot_mag_max,\n",
    "    'train_rot_mag_min': train_rot_mag_min,\n",
    "    'train_rot_mag_max': train_rot_mag_max,\n",
    "    'model_path': MODEL_SAVE_PATH,\n",
    "    'eval_path' : eval_path\n",
    "}\n",
    "\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_path, 'a', newline='') as csvfile:\n",
    "    fieldnames = csv_data.keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(csv_data)\n",
    "\n",
    "print(f\"Results appended to CSV: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
